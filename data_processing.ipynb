{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f773d85",
   "metadata": {},
   "source": [
    "# Import Libraries #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ddfd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import math\n",
    "# from datetime import datetime, timedelta\n",
    "import os\n",
    "# import re\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# OLGA: Define the patient ID for processing\n",
    "patient_id = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b215109e",
   "metadata": {},
   "source": [
    "# Load Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_file_format(filepath):\n",
    "    \"\"\"\n",
    "    Detect the file format and separator\n",
    "    \"\"\"\n",
    "    # Try different separators\n",
    "    separators = [',', '|', '\\t', ';']\n",
    "    \n",
    "    for sep in separators:\n",
    "        try:\n",
    "            # Read first few rows to check format\n",
    "            sample = pd.read_csv(filepath, sep=sep, nrows=5)\n",
    "            if len(sample.columns) >= 2:  # At least 2 columns\n",
    "                return sep\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return ','  # Default to comma\n",
    "\n",
    "def identify_columns(df):\n",
    "    \"\"\"\n",
    "    Identify which columns contain time and glucose data\n",
    "    \"\"\"\n",
    "    time_col = None\n",
    "    glucose_col = None\n",
    "    \n",
    "    # Common time column names\n",
    "    time_patterns = [\n",
    "        'time', 'timestamp', 'datetime', 'date', 'datadttm', \n",
    "        'data_dt_tm', 'recorded_time', 'measurement_time'\n",
    "    ]\n",
    "    \n",
    "    # Common glucose column names\n",
    "    glucose_patterns = [\n",
    "        'glucose', 'cgm', 'bg', 'blood_glucose', 'sensor_glucose',\n",
    "        'glucose_level', 'gl', 'sensor_value', 'reading', 'value'\n",
    "    ]\n",
    "    \n",
    "    # Check column names (case insensitive)\n",
    "    columns_lower = [col.lower() for col in df.columns]\n",
    "    \n",
    "    # Find time column\n",
    "    for pattern in time_patterns:\n",
    "        for i, col in enumerate(columns_lower):\n",
    "            if pattern in col:\n",
    "                time_col = df.columns[i]\n",
    "                break\n",
    "        if time_col:\n",
    "            break\n",
    "    \n",
    "    # Find glucose column\n",
    "    for pattern in glucose_patterns:\n",
    "        for i, col in enumerate(columns_lower):\n",
    "            if pattern in col:\n",
    "                glucose_col = df.columns[i]\n",
    "                break\n",
    "        if glucose_col:\n",
    "            break\n",
    "    \n",
    "    # If not found by name, try to identify by data type and content\n",
    "    if not time_col:\n",
    "        for col in df.columns:\n",
    "            # Check if column contains datetime-like strings\n",
    "            sample_val = str(df[col].dropna().iloc[0]) if not df[col].dropna().empty else \"\"\n",
    "            if any(char in sample_val for char in [':', '-', '/', ' ']) and len(sample_val) > 8:\n",
    "                time_col = col\n",
    "                break\n",
    "    \n",
    "    if not glucose_col:\n",
    "        for col in df.columns:\n",
    "            if col != time_col:  # Don't use the time column\n",
    "                try:\n",
    "                    # Check if column is numeric and within reasonable glucose range\n",
    "                    numeric_data = pd.to_numeric(df[col], errors='coerce').dropna()\n",
    "                    if len(numeric_data) > 0:\n",
    "                        min_val, max_val = numeric_data.min(), numeric_data.max()\n",
    "                        # Typical glucose range is 20-600 mg/dL\n",
    "                        if 20 <= min_val <= 600 and 20 <= max_val <= 600:\n",
    "                            glucose_col = col\n",
    "                            break\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return time_col, glucose_col\n",
    "\n",
    "def detect_timestamp_format(timestamp_str, possible_formats=None):\n",
    "    \"\"\"\n",
    "    Try to detect timestamp with multiple possible formats\n",
    "    \"\"\"\n",
    "    if possible_formats is None:\n",
    "        possible_formats = [\n",
    "            \"%d%b%y:%H:%M:%S\",  # Original format\n",
    "            \"%Y-%m-%d %H:%M:%S\",\n",
    "            \"%m/%d/%Y %H:%M:%S\",\n",
    "            \"%d/%m/%Y %H:%M:%S\",\n",
    "            \"%Y-%m-%d %H:%M\",\n",
    "            \"%m/%d/%Y %H:%M\",\n",
    "            \"%d/%m/%Y %H:%M\",\n",
    "            \"%Y-%m-%d\",\n",
    "            \"%m/%d/%Y\",\n",
    "            \"%d/%m/%Y\",\n",
    "            \"%d-%b-%Y %H:%M:%S\",\n",
    "            \"%d-%b-%y %H:%M:%S\",\n",
    "            \"%Y%m%d %H:%M:%S\",\n",
    "            \"%d%m%Y %H:%M:%S\"\n",
    "        ]\n",
    "    \n",
    "    for fmt in possible_formats:\n",
    "        try:\n",
    "            pd.to_datetime(timestamp_str, format=fmt)\n",
    "            return fmt\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51199a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_cgm_data(filepath, output_filename=\"standardized_cgm_data.csv\"):\n",
    "    \"\"\"\n",
    "    Read CGM data file and standardize it to time|glucose_level format\n",
    "    \"\"\"\n",
    "    print(f\"Processing file: {filepath}\")\n",
    "    \n",
    "    # Detect file format\n",
    "    separator = detect_file_format(filepath)\n",
    "    print(f\"Detected separator: '{separator}'\")\n",
    "    \n",
    "    # Read the file\n",
    "    try:\n",
    "        # Try reading with headers first\n",
    "        df = pd.read_csv(filepath, sep=separator)\n",
    "        print(f\"File loaded with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "        \n",
    "        # If first row might be data (no clear headers), try skiprows=1 \n",
    "        # OLGA: if your file has no header, you will need to use header=None, not skiprows=1, otheerwise you will skip the first row of data\n",
    "        if len(df.columns) <= 2 and any(col.startswith('Unnamed') for col in df.columns):\n",
    "            df = pd.read_csv(filepath, sep=separator, header=None, \n",
    "                           names=[\"col1\", \"col2\"] if len(df.columns) == 2 else [f\"col{i+1}\" for i in range(len(df.columns))])\n",
    "            print(\"Retried with header=None and custom column names\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Identify time and glucose columns\n",
    "    time_col, glucose_col = identify_columns(df)\n",
    "    \n",
    "    if not time_col or not glucose_col:\n",
    "        print(\"Could not automatically identify time and glucose columns.\")\n",
    "        print(\"Available columns:\", list(df.columns))\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # For now, make educated guesses based on position\n",
    "        if len(df.columns) >= 2:\n",
    "            time_col = df.columns[0]  # First column often time\n",
    "            glucose_col = df.columns[1] if len(df.columns) == 2 else df.columns[-1]  # Last column often glucose\n",
    "            print(f\"Using best guess - Time: {time_col}, Glucose: {glucose_col}\")\n",
    "    \n",
    "    print(f\"Identified columns - Time: {time_col}, Glucose: {glucose_col}\")\n",
    "    \n",
    "    # Extract and clean the data\n",
    "    clean_df = df[[time_col, glucose_col]].copy()\n",
    "    clean_df.columns = ['time', 'glucose_level']\n",
    "    \n",
    "    # Remove rows with missing data\n",
    "    clean_df = clean_df.dropna()\n",
    "    \n",
    "    # Parse timestamps\n",
    "    # OLGA: do format detection using small sample of data insteadof the complete dataset\n",
    "    print(\"Parsing timestamps...\")\n",
    "    timestamp_sample = clean_df['time'].head(5)\n",
    "    timestamp_fmt = detect_timestamp_format(timestamp_sample)\n",
    "    if timestamp_fmt:\n",
    "        print(f\"Detected timestamp format: {timestamp_fmt}\")\n",
    "        clean_df['time'] = pd.to_datetime(clean_df['time'], format=timestamp_fmt, errors='coerce')\n",
    "    else:\n",
    "        print(\"Could not detect timestamp format, using general parser\")\n",
    "        clean_df['time'] = pd.to_datetime(clean_df['time'],  errors='coerce')    \n",
    "    \n",
    "    # Remove rows where timestamp parsing failed\n",
    "    clean_df = clean_df[clean_df['time'].notna()]\n",
    "    \n",
    "    # Convert glucose to numeric\n",
    "    clean_df['glucose_level'] = pd.to_numeric(clean_df['glucose_level'], errors='coerce')\n",
    "    clean_df = clean_df[clean_df['glucose_level'].notna()]\n",
    "    \n",
    "    # Remove duplicates and sort by time\n",
    "    clean_df = clean_df.drop_duplicates()\n",
    "    clean_df = clean_df.sort_values('time')\n",
    "\n",
    "    #OLGA: drop index\n",
    "    clean_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Validate glucose values (reasonable range)\n",
    "    initial_count = len(clean_df)\n",
    "    clean_df = clean_df[(clean_df['glucose_level'] >= 20) & (clean_df['glucose_level'] <= 600)]\n",
    "    filtered_count = initial_count - len(clean_df)\n",
    "    if filtered_count > 0:\n",
    "        print(f\"Filtered out {filtered_count} readings with unrealistic glucose values\")\n",
    "    \n",
    "    print(f\"Final dataset: {len(clean_df)} readings\")\n",
    "    print(f\"Date range: {clean_df['time'].min()} to {clean_df['time'].max()}\")\n",
    "    print(f\"Glucose range: {clean_df['glucose_level'].min():.1f} to {clean_df['glucose_level'].max():.1f} mg/dL\")\n",
    "    \n",
    "    # Save standardized data\n",
    "    clean_df.to_csv(output_filename, sep='|', index=False)\n",
    "    print(f\"Standardized data saved to: {output_filename}\")\n",
    "    \n",
    "    # Display sample\n",
    "    print(\"\\nSample of standardized data:\")\n",
    "    print(clean_df.head())\n",
    "    \n",
    "    return clean_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd339611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLGA: process cgm.txt to create patient-specific data files\n",
    "\n",
    "def process_patient_data(cgm_df, patient_id):\n",
    "    print(f\"Processing data for patient: {patient_id}\")\n",
    "    patient_data = cgm_df[cgm_df['PtID'] == patient_id]\n",
    "    \n",
    "    # Save patient-specific data\n",
    "    patient_filename = f\"data/cgm_{patient_id}.csv\"\n",
    "    patient_data.to_csv(patient_filename, index=False)\n",
    "    print(f\"Patient data saved to: {patient_filename}\")\n",
    "\n",
    "cgmdata = \"data/cgm.txt\"\n",
    "\n",
    "# Load raw file\n",
    "cgm_df = pd.read_csv(\n",
    "    cgmdata,\n",
    "    sep=\"|\",\n",
    ")\n",
    "\n",
    "\n",
    "if patient_id:\n",
    "    process_patient_data(cgm_df, patient_id)\n",
    "else:    \n",
    "    for patient_id in cgm_df['PtID'].unique():\n",
    "        process_patient_data(cgm_df, patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325162e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beae297",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Update this path to your CGM data file\n",
    "cgm_file_path = \"data/cgm_10.csv\"\n",
    "\n",
    "# Standardize the CGM data\n",
    "df_patient = standardize_cgm_data(cgm_file_path, \"data/standardized_cgm_data.csv\")\n",
    "\n",
    "if df_patient is not None:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STANDARDIZATION COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Output file: data/standardized_cgm_data.csv\")\n",
    "    print(f\"Format: time|glucose_level\")\n",
    "    print(f\"Records: {len(df_patient)}\")\n",
    "else:\n",
    "    print(\"Standardization failed. Please check the file format and try again.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2c7456",
   "metadata": {},
   "source": [
    "# Clean and Pre-Process Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLGA: you already cleaned the dataset\n",
    "# # Clean and Pre-Process Data\n",
    "# df = df.drop_duplicates()\n",
    "# df = df.dropna()\n",
    "\n",
    "# Rename columns to match existing analysis code\n",
    "df_patient = df_patient.rename(columns={'time': 'DataDtTm', 'glucose_level': 'CGM'})\n",
    "\n",
    "# OLGA this columnt is not needed, as we assume single patient data\n",
    "# # Add a patient ID since standardized data doesn't have one\n",
    "# df['iPtID'] = 1  # Single patient assumption\n",
    "\n",
    "print(\"Standardized data loaded and cleaned:\")\n",
    "print(f\"Date range: {df_patient['DataDtTm'].min()} to {df_patient['DataDtTm'].max()}\")\n",
    "print(f\"Total readings: {len(df_patient)}\")\n",
    "print(df_patient.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908302ed",
   "metadata": {},
   "source": [
    "# Seperating by Day #\n",
    "Testing with one Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient_id = 1\n",
    "# df_patient = df[df['iPtID'] == patient_id].copy()\n",
    "\n",
    "latest_date = df_patient['DataDtTm'].max()\n",
    "start_date = latest_date - pd.Timedelta(days=30)\n",
    "\n",
    "df_patient = df_patient[df_patient[\"DataDtTm\"] >= start_date]\n",
    "df_patient = df_patient.sort_values('DataDtTm')\n",
    "\n",
    "print(f\"Patient {patient_id} data:\")\n",
    "print(f\"Date range: {df_patient['DataDtTm'].min()} to {df_patient['DataDtTm'].max()}\")\n",
    "print(f\"Total readings: {len(df_patient)}\")\n",
    "print(f\"Days of data: {(df_patient['DataDtTm'].max() - df_patient['DataDtTm'].min()).days + 1}\")\n",
    "\n",
    "df_patient.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970014e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_daily_summaries_csv(df_patient, output_filename=\"daily_cgm_summaries.csv\"):\n",
    "    \"\"\"Create daily summaries of CGM data and save directly as CSV\"\"\"\n",
    "    \n",
    "    # Add date column for grouping\n",
    "    df_patient['Date'] = df_patient['DataDtTm'].dt.date\n",
    "    \n",
    "    # Initialize lists to store summary data\n",
    "    dates = []\n",
    "    # patient_ids = []\n",
    "    mean_glucose = []\n",
    "    std_dev = []\n",
    "    glucose_range = []\n",
    "    pct_high = []\n",
    "    pct_low = []\n",
    "    pct_in_range = []\n",
    "    time_high_hours = []\n",
    "    time_low_hours = []\n",
    "    time_in_range_hours = []\n",
    "    max_glucose = []\n",
    "    min_glucose = []\n",
    "    time_of_peak = []\n",
    "    time_of_lowest = []\n",
    "    readings_count = []\n",
    "    day_of_week = []\n",
    "    \n",
    "    # Group by date and calculate metrics\n",
    "    grouped = df_patient.groupby('Date')\n",
    "    \n",
    "    for date, group in grouped:\n",
    "        glucose = group[\"CGM\"]\n",
    "        \n",
    "        # Basic statistics\n",
    "        dates.append(str(date))\n",
    "        # patient_ids.append(int(group['iPtID'].iloc[0]))\n",
    "        mean_glucose.append(round(glucose.mean(), 2))\n",
    "        std_dev.append(round(glucose.std(), 2))\n",
    "        \n",
    "        # Range calculations\n",
    "        max_val = glucose.max()\n",
    "        min_val = glucose.min()\n",
    "        max_glucose.append(max_val)\n",
    "        min_glucose.append(min_val)\n",
    "        glucose_range.append(max_val - min_val)\n",
    "        \n",
    "        # Percentage calculations\n",
    "        pct_high.append(round((glucose > 180).mean() * 100, 2))\n",
    "        pct_low.append(round((glucose < 70).mean() * 100, 2))\n",
    "        pct_in_range.append(round(((glucose >= 70) & (glucose <= 180)).mean() * 100, 2))\n",
    "        \n",
    "        # Time-based analysis (assuming 5-minute intervals)\n",
    "        time_high_hours.append(round((glucose > 180).sum() * 5 / 60, 1))\n",
    "        time_low_hours.append(round((glucose < 70).sum() * 5 / 60, 1))\n",
    "        time_in_range_hours.append(round(((glucose >= 70) & (glucose <= 180)).sum() * 5 / 60, 1))\n",
    "        \n",
    "        # Peak and lowest times\n",
    "        time_of_peak.append(group.loc[glucose.idxmax(), \"DataDtTm\"].strftime(\"%H:%M\"))\n",
    "        time_of_lowest.append(group.loc[glucose.idxmin(), \"DataDtTm\"].strftime(\"%H:%M\"))\n",
    "        \n",
    "        # Additional metrics\n",
    "        readings_count.append(len(glucose))\n",
    "        day_of_week.append(pd.to_datetime(date).strftime(\"%A\"))\n",
    "    \n",
    "    # Create DataFrame directly\n",
    "    daily_summaries_df = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        #'PatientID': patient_id,\n",
    "        'DayOfWeek': day_of_week,\n",
    "        'MeanGlucose': mean_glucose,\n",
    "        'StdDev': std_dev,\n",
    "        'GlucoseRange': glucose_range,\n",
    "        'PercentHigh': pct_high,\n",
    "        'PercentLow': pct_low,\n",
    "        'PercentInRange': pct_in_range,\n",
    "        'TimeHighHours': time_high_hours,\n",
    "        'TimeLowHours': time_low_hours,\n",
    "        'TimeInRangeHours': time_in_range_hours,\n",
    "        'MaxGlucose': max_glucose,\n",
    "        'MinGlucose': min_glucose,\n",
    "        'TimeOfPeak': time_of_peak,\n",
    "        'TimeOfLowest': time_of_lowest,\n",
    "        'ReadingsCount': readings_count\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    daily_summaries_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Daily summaries saved to {output_filename}\")\n",
    "    \n",
    "    return daily_summaries_df\n",
    "\n",
    "# Generate the CSV file\n",
    "daily_df = create_daily_summaries_csv(df_patient, \"data/daily_cgm_summaries.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"Generated {len(daily_df)} daily summaries:\")\n",
    "print(\"\\nFirst 3 days summary:\")\n",
    "for i in range(min(3, len(daily_df))):\n",
    "    row = daily_df.iloc[i]\n",
    "    print(f\"\\nDate: {row['Date']} ({row['DayOfWeek']})\")\n",
    "    print(f\"Mean Glucose: {row['MeanGlucose']} mg/dL\")\n",
    "    print(f\"Time in Range (70-180): {row['PercentInRange']}% ({row['TimeInRangeHours']} hours)\")\n",
    "    print(f\"Time High (>180): {row['PercentHigh']}% ({row['TimeHighHours']} hours)\")\n",
    "    print(f\"Time Low (<70): {row['PercentLow']}% ({row['TimeLowHours']} hours)\")\n",
    "    print(f\"Peak: {row['MaxGlucose']} at {row['TimeOfPeak']}\")\n",
    "\n",
    "# Display the DataFrame\n",
    "daily_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_period_summary_csv(daily_df, days, output_filename=None):\n",
    "    \"\"\"Create summary for last N days and save as CSV\"\"\"\n",
    "    \n",
    "\n",
    "    # Adjust days if we don't have enough data\n",
    "    if len(daily_df) < days:\n",
    "        days = len(daily_df)\n",
    "    \n",
    "    # Get the most recent N days\n",
    "    # OLGA: sort by date to ensure we get the last N days correctly\n",
    "    daily_df.sort_values(by='Date', ascending=True, inplace=True) \n",
    "    recent_days = daily_df.tail(days)\n",
    "    \n",
    "    # Calculate averages using pandas operations\n",
    "    mean_glucose = round(recent_days['MeanGlucose'].mean(), 2)\n",
    "    mean_std = round(recent_days['StdDev'].mean(), 2)\n",
    "    mean_pct_high = round(recent_days['PercentHigh'].mean(), 2)\n",
    "    mean_pct_low = round(recent_days['PercentLow'].mean(), 2)\n",
    "    mean_pct_in_range = round(recent_days['PercentInRange'].mean(), 2)\n",
    "    \n",
    "    # Calculate glucose variability (std of daily means)\n",
    "    cgm_variability = round(recent_days['MeanGlucose'].std(), 2)\n",
    "    \n",
    "    # Calculate average time metrics\n",
    "    avg_time_high = round(recent_days['TimeHighHours'].mean(), 2)\n",
    "    avg_time_low = round(recent_days['TimeLowHours'].mean(), 2)\n",
    "    avg_time_in_range = round(recent_days['TimeInRangeHours'].mean(), 2)\n",
    "    \n",
    "    # Get max and min values\n",
    "    max_daily_glucose = recent_days['MaxGlucose'].max()\n",
    "    min_daily_glucose = recent_days['MinGlucose'].min()\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Period': [f\"Last {days} days\"],\n",
    "        'StartDate': [recent_days['Date'].iloc[0]],\n",
    "        'EndDate': [recent_days['Date'].iloc[-1]],\n",
    "        'MeanGlucose': [mean_glucose],\n",
    "        'GlucoseVariability': [cgm_variability],\n",
    "        'MeanStdDev': [mean_std],\n",
    "        'AvgPercentHigh': [mean_pct_high],\n",
    "        'AvgPercentLow': [mean_pct_low],\n",
    "        'AvgPercentInRange': [mean_pct_in_range],\n",
    "        'AvgTimeHighHours': [avg_time_high],\n",
    "        'AvgTimeLowHours': [avg_time_low],\n",
    "        'AvgTimeInRangeHours': [avg_time_in_range],\n",
    "        'MaxGlucoseObserved': [max_daily_glucose],\n",
    "        'MinGlucoseObserved': [min_daily_glucose],\n",
    "        'TotalDays': [days]\n",
    "    })\n",
    "    \n",
    "    # Save to CSV if filename provided\n",
    "    if output_filename:\n",
    "        summary_df.to_csv(output_filename, index=False)\n",
    "        print(f\"Period summary saved to {output_filename}\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Generate summaries\n",
    "summary_7_days_df = create_period_summary_csv(daily_df, 7, \"data/7_day_summary.csv\")\n",
    "summary_30_days_df = create_period_summary_csv(daily_df, 30, \"data/30_day_summary.csv\")\n",
    "\n",
    "# Display results\n",
    "print(\"7-Day Summary:\")\n",
    "for col in summary_7_days_df.columns:\n",
    "    print(f\"{col}: {summary_7_days_df[col].iloc[0]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"30-Day Summary:\")\n",
    "for col in summary_30_days_df.columns:\n",
    "    print(f\"{col}: {summary_30_days_df[col].iloc[0]}\")\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"\\n7-Day Summary DataFrame:\")\n",
    "print(summary_7_days_df)\n",
    "\n",
    "print(\"\\n30-Day Summary DataFrame:\")\n",
    "print(summary_30_days_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6592070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_llm_analysis_csv(daily_df, patient_id, summary_7_days_df, summary_30_days_df, output_filename=\"cgm_analysis_report.txt\"):\n",
    "    \"\"\"Format CGM data in a readable format for LLM analysis\"\"\"\n",
    "    \n",
    "    # Extract values from DataFrames\n",
    "    # patient_id = daily_df['PatientID'].iloc[0]\n",
    "    start_date = summary_30_days_df['StartDate'].iloc[0]\n",
    "    end_date = summary_30_days_df['EndDate'].iloc[0]\n",
    "    \n",
    "    # Create the LLM report text\n",
    "    llm_report = f\"\"\"\n",
    "CGM DATA ANALYSIS REPORT\n",
    "Patient ID: {patient_id}\n",
    "Analysis Period: {start_date} to {end_date}\n",
    "\n",
    "RECENT PERIOD SUMMARIES:\n",
    "\n",
    "Last 7 Days:\n",
    "- Average Glucose: {summary_7_days_df['MeanGlucose'].iloc[0]} mg/dL\n",
    "- Time in Range (70-180 mg/dL): {summary_7_days_df['AvgPercentInRange'].iloc[0]}%\n",
    "- Time Above Range (>180 mg/dL): {summary_7_days_df['AvgPercentHigh'].iloc[0]}%\n",
    "- Time Below Range (<70 mg/dL): {summary_7_days_df['AvgPercentLow'].iloc[0]}%\n",
    "- Glucose Variability: {summary_7_days_df['GlucoseVariability'].iloc[0]} mg/dL\n",
    "- Average Daily High Time: {summary_7_days_df['AvgTimeHighHours'].iloc[0]} hours\n",
    "- Average Daily Low Time: {summary_7_days_df['AvgTimeLowHours'].iloc[0]} hours\n",
    "\n",
    "Last 30 Days:\n",
    "- Average Glucose: {summary_30_days_df['MeanGlucose'].iloc[0]} mg/dL\n",
    "- Time in Range (70-180 mg/dL): {summary_30_days_df['AvgPercentInRange'].iloc[0]}%\n",
    "- Time Above Range (>180 mg/dL): {summary_30_days_df['AvgPercentHigh'].iloc[0]}%\n",
    "- Time Below Range (<70 mg/dL): {summary_30_days_df['AvgPercentLow'].iloc[0]}%\n",
    "- Glucose Variability: {summary_30_days_df['GlucoseVariability'].iloc[0]} mg/dL\n",
    "- Highest Glucose Observed: {summary_30_days_df['MaxGlucoseObserved'].iloc[0]} mg/dL\n",
    "- Lowest Glucose Observed: {summary_30_days_df['MinGlucoseObserved'].iloc[0]} mg/dL\n",
    "\n",
    "DAILY BREAKDOWN (Last 14 Days):\n",
    "\"\"\"\n",
    "\n",
    "    # Get last 14 days for detailed breakdown\n",
    "    recent_14_days = daily_df.tail(14)\n",
    "    \n",
    "    # Add daily details for pattern recognition\n",
    "    for idx, row in recent_14_days.iterrows():\n",
    "        llm_report += f\"\"\"\n",
    "{row['Date']} ({row['DayOfWeek']}):\n",
    "  Mean: {row['MeanGlucose']} mg/dL | Range: {row['MinGlucose']}-{row['MaxGlucose']} mg/dL\n",
    "  Time in Range: {row['PercentInRange']}% | High: {row['PercentHigh']}% | Low: {row['PercentLow']}%\n",
    "  Peak at {row['TimeOfPeak']} ({row['MaxGlucose']} mg/dL) | Lowest at {row['TimeOfLowest']} ({row['MinGlucose']} mg/dL)\n",
    "  Standard Deviation: {row['StdDev']} mg/dL\n",
    "\"\"\"\n",
    "    \n",
    "    # Save the text report\n",
    "    with open(output_filename, \"w\") as f:\n",
    "        f.write(llm_report)\n",
    "    print(f\"Report saved to '{output_filename}'\")\n",
    "    \n",
    "    return llm_report\n",
    "\n",
    "# Generate the analysis\n",
    "# OLGA: moved output file to data subfolder for consistency\n",
    "llm_analysis_text = format_for_llm_analysis_csv(daily_df, patient_id, summary_7_days_df, summary_30_days_df, \"data/cgm_analysis_report.txt\")\n",
    "\n",
    "print(\"LLM Analysis Report Generated:\")\n",
    "print(\"=\"*60)\n",
    "print(llm_analysis_text[:1000] + \"...\" if len(llm_analysis_text) > 1000 else llm_analysis_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
